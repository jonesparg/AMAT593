{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with Matrix Factorization\n",
    "\n",
    "[Collaborative filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) (CF) aims to fill in the missing entries of a user-item rating matrix with predicted ratings, so that users are recomended new items based on the predicted ratings. \n",
    "\n",
    "In generally, there are two approaches for collaborative filtering: memory-based CF and model-based CF. In this notebook, we will focus on model-based approach, in which models are developed using different machine learning algorithms to predict users' rating of unrated items. Here we will introduce the most popular matrix factorization model.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/yin-penghang/AMAT593/blob/main/figs/15_CF.png?raw=true\" width = '400'>\n",
    "\n",
    "## Matrix Factorization\n",
    "\n",
    "Model-based collaborative filtering is an application of matrix factorization to identify the relationship between items’ and users’ entities. With the input of users’ ratings on the items, we would like to predict how the users would rate the items so the users can get the recommendation based on the prediction.\n",
    "\n",
    "Suppose we have the user-item rating matrix $\\mathbf{R}$ for $m$ users and $n$ items, and the ratings are integers ranging from 1 to 5:\n",
    "\n",
    "<img src= 'https://github.com/yin-penghang/AMAT593/blob/main/figs/15_rating_matrix.png?raw=true' width = '800'>\n",
    "\n",
    "The $(i,j)$-th entry $r_{i,j}$ represents the $i$-th user's rating on the $j$-th item.\n",
    "The rating matrix $\\mathbf{R}\\in\\mathbb{R}^{m\\times n}$ has a large portion of entries/ratings missing, and our goal here is to impute the full matrix. \n",
    "\n",
    "Matrix factorization model assumes: every item has $k$ **latent factors** based on which a user will give the rating, where **$k$ is much less than the number of users and the number of items**. Maybe one factor means \"movies with frantic chases\", another factor might mean \"movies with a plot twist\", etc. \n",
    "\n",
    "Let $\\mathbf{q}_j \\in\\mathbb{R}^k$ be the $j$-th item's **components** in the $k$ latent factors and $\\mathbf{p}_i\\in\\mathbb{R}^k$ be the $i$-th user's **personal preferences** on these $k$ latent factors, e.g.,\n",
    "\n",
    "    Movie j = 0.5 x frantic chases + 0.2 x plot twist + ...\n",
    "    \n",
    "    User i = 0.3 x fan of frantic chases + 1.8 x fan of plot twist + ...\n",
    "\n",
    "In practice, the latent factors are opaque. Given $\\mathbf{q}_j$ and $\\mathbf{p}_i$, the model generates the rating:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{i,j} = \\mathbf{p}_i^\\top \\mathbf{q}_j\n",
    "$$\n",
    "\n",
    "In matrix form, denote by $\\mathbf{P} = \\begin{bmatrix} -  \\mathbf{p}_1^\\top - \\\\ \\cdots \\\\ -  \\mathbf{p}_m^\\top - \\end{bmatrix}\\in\\mathbb{R}^{m\\times k}$ the user latent matrix (with transpose), and $\\mathbf{Q} = \\begin{bmatrix} | \\qquad | \\\\ \\mathbf{q}_1 \\cdots \\mathbf{q}_n \\\\ | \\qquad | \\end{bmatrix}\\in\\mathbb{R}^{k\\times n}$ the item latent matrix, then the predicted rating matrix has the **low-rank matrix factorization**\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{R}} = \\mathbf{P} \\, \\mathbf{Q}\\in\\mathbb{R}^{m\\times n}\n",
    "$$\n",
    "\n",
    "<img src='https://github.com/yin-penghang/AMAT593/blob/main/figs/15_MatFacto.png?raw=true' width = '500'>\n",
    "\n",
    "For any observed rating $r_{i,j}\\in\\mathbf{R}$, $\\hat{\\mathbf{R}}$ satisfies \n",
    "\n",
    "$$\n",
    "\\hat{r}_{i,j} = \\mathbf{p}_i^\\top \\mathbf{q}_j = r_{i,j}.\n",
    "$$\n",
    "\n",
    "**Under the constraints above, we aim to infer the user latent matrix $\\mathbf{P}$ and item latent matrix $\\mathbf{Q}$** by solving\n",
    "\n",
    "$$\n",
    "\\min_{\\{\\mathbf{p}_i\\}_{i=1}^m, \\{\\mathbf{q}_j\\}_{j=1}^n} \\; \\sum_{\\mbox{ observed } r_{i,j}} (r_{i,j} - \\mathbf{p}_i^\\top \\mathbf{q}_j)^2\n",
    "+ \\lambda(\\|\\mathbf{p}_i\\|^2 + \\|\\mathbf{q}_j\\|^2)\n",
    "$$\n",
    "\n",
    "The model could be more sophisticated by factoring in, for example, the bias of each user towards the rating system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Matrix Factorization Algorithm\n",
    "\n",
    "The minimization is performed by a straightforward stochastic gradient descent: for observed $r_{i,j}$, iterate\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{p}_i \\leftarrow \\mathbf{p}_i - \\eta  \\left( (\\mathbf{p}_i^\\top \\mathbf{q}_j - r_{i,j})\\mathbf{q}_j + \\lambda \\mathbf{p}_i \\right) \\\\\n",
    "\\mathbf{q}_j \\leftarrow \\mathbf{q}_j - \\eta  \\left( (\\mathbf{p}_i^\\top \\mathbf{q}_j - r_{i,j})\\mathbf{p}_i + \\lambda \\mathbf{q}_j \\right)\n",
    "\\end{align}\n",
    "\n",
    "The above iterations are known as the SVD algorithm, as popularized by [Simon Funk](https://sifter.org/~simon/journal/20061211.html) during the Netflix Prize, although \n",
    "**it is actually NOT [SVD](https://en.wikipedia.org/wiki/Singular_value_decomposition) which computes the factorization of a full matrix.** The more appropriate term for what Funk did is **matrix factorization**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation\n",
    "\n",
    "Our matrix factorization implementation is based on [``surprise``](https://surprise.readthedocs.io/en/stable/index.html#) library.\n",
    "\n",
    "### Surprise Library\n",
    "\n",
    "``surprise`` is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
    "\n",
    "* give users perfect control over their experiments.\n",
    "\n",
    "* alleviate the pain of Dataset handling. Users can use both built-in datasets (Movielens, Jester), and custom datasets.\n",
    "\n",
    "* provide various ready-to-use prediction algorithms and various built-in similarity measures.\n",
    "\n",
    "* make it easy to implement new algorithm ideas.\n",
    "\n",
    "* similar to ``sklearn``, provide tools to evaluate, analyse and compare the algorithms’ performance, such as cross-validation and hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import surprise\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custum algorithm is a class derived from ``AlgoBase`` that has an ``estimate`` method. ``AlgoBase`` is an abstract class that defines the basic behavior of a prediciton algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFacto(surprise.AlgoBase):\n",
    "    '''A basic rating prediction algorithm based on matrix factorization.'''\n",
    "    \n",
    "    def __init__(self, n_factors, n_epochs,  learning_rate=0.05, reg_param=0.0):\n",
    "        \n",
    "        self.lr = learning_rate  # learning rate for SGD\n",
    "        self.n_epochs = n_epochs  # number of iterations of SGD\n",
    "        self.n_factors = n_factors  # number of factors\n",
    "        self.lam = reg_param # regularization parameter\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        \n",
    "        print('Fitting data with SGD...')\n",
    "        \n",
    "        # Randomly initialize the user and item factors.\n",
    "        p = np.random.normal(0, .1, (trainset.n_users, self.n_factors))\n",
    "        q = np.random.normal(0, .1, (trainset.n_items, self.n_factors))\n",
    "        \n",
    "        # SGD procedure\n",
    "        for _ in range(self.n_epochs):\n",
    "            for i, j, r_ij in trainset.all_ratings():\n",
    "                err =  np.dot(p[i], q[j]) - r_ij\n",
    "                # Update vectors p_u and q_i\n",
    "                p[i] -= self.lr * (err * q[j] + self.lam * p[i])\n",
    "                q[j] -= self.lr * (err * p[i] + self.lam * q[j])\n",
    "        \n",
    "        self.p, self.q = p, q\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, i, j):\n",
    "        '''Return the estmimated rating of user u for item i.'''\n",
    "        \n",
    "        # return scalar product between p_i and q_j if user and item are known,\n",
    "        # return np.dot(self.p[i], self.q[j])\n",
    "        \n",
    "        if self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
    "            return np.dot(self.p[i], self.q[j])\n",
    "        else:\n",
    "            return self.trainset.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens Dataset\n",
    "\n",
    "MovieLens small dataset contains ~100,000 ratings from ~600 users on ~9700 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading ratings file\n",
    "ratings = pd.read_csv('ratings.csv', sep=',', encoding='latin-1', usecols=['userId','movieId','rating'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', sep=',', encoding='latin-1', usecols=['movieId','title','genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 610\n",
      "Number of movies = 9724\n"
     ]
    }
   ],
   "source": [
    "n_users = ratings.userId.unique().shape[0]\n",
    "n_movies = ratings.movieId.unique().shape[0]\n",
    "print('Number of users = ' + str(n_users) + '\\nNumber of movies = ' + str(n_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the data from ``DataFrame`` using ``surprie``'s ``Dataset.load_from_df`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reader library\n",
    "reader = Reader()\n",
    "\n",
    "# Load ratings dataset with Dataset library\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check the sparsity of the ratings dataset, i.e., the percentage of missing ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of MovieLens dataset is 98.3%\n"
     ]
    }
   ],
   "source": [
    "sparsity = round(1.0 - len(ratings) / float(n_users * n_movies), 3)\n",
    "print('The sparsity level of MovieLens dataset is ' +  str(sparsity * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split for the dataset, use 80% of the ratings for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a ``MatrixFacto``  algorithm object with specified hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_MF = MatrixFacto(n_factors=50, n_epochs=30, learning_rate=.02, reg_param = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data with SGD...\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "algo_MF.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix factorization test RMSE: 0.8957\n"
     ]
    }
   ],
   "source": [
    "test_pred = algo_MF.test(testset)\n",
    "print(\"Matrix factorization test RMSE: {0:0.4f}\".format(accuracy.rmse(test_pred, verbose=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>3744</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>3793</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>3809</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>4006</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>5060</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  movieId  rating\n",
       "0         1        1     4.0\n",
       "1         1        3     4.0\n",
       "2         1        6     4.0\n",
       "3         1       47     5.0\n",
       "4         1       50     5.0\n",
       "..      ...      ...     ...\n",
       "227       1     3744     4.0\n",
       "228       1     3793     5.0\n",
       "229       1     3809     4.0\n",
       "230       1     4006     4.0\n",
       "231       1     5060     5.0\n",
       "\n",
       "[232 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings['userId'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the rating that User with ID 1 will give to a random movie, say with Movie ID 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6702695640727425"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_MF.estimate(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For movie with ID 1994, the estimated prediction of 2.95. The recommender system works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7569033133215415"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_MF.estimate(1, 1) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4342960889754646"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_MF.estimate(1, 3809) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1053740215436374"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_MF.estimate(1, 47) # true rating 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.360470823056238"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_MF.estimate(1, 4006) # true rating 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``surprise`` SVD Built-in Method\n",
    "\n",
    "``surprise``'s ``SVD`` implementation is more sophisticated than ours, which takes into account the so-called user bias and item bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise's SVD Test RMSE: : 0.8520\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "algo_svd = SVD(n_factors=50, n_epochs=30, lr_all=0.02, reg_all=0.1)\n",
    "\n",
    "algo_svd.fit(trainset)\n",
    "test_pred = algo_svd.test(testset)\n",
    "print(\"Surprise's SVD Test RMSE: : {0:0.4f}\".format(accuracy.rmse(test_pred, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8933963399402014"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svd.estimate(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.575428050579162"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svd.estimate(1, 1) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2934135826939945"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svd.estimate(1, 47) # true rating 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.395859590451415"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svd.estimate(1, 3809) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.382873600325466"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svd.estimate(1, 4006) # true rating 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``surprise`` SVD++ Built-in Method\n",
    "\n",
    "``surprise`` also provides built-in algorithm ``SVDpp`` for SVD++, which is an improvement over ``SVD``. However, it is much slower than ``SVD`` (it will take a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD++ Test RMSE: : 0.8509\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVDpp\n",
    "\n",
    "algo_svdpp = SVDpp(n_factors=50, n_epochs=30, lr_all=0.02, reg_all=0.1)\n",
    "\n",
    "algo_svdpp.fit(trainset)\n",
    "test_pred = algo_svdpp.test(testset)\n",
    "print(\"SVD++ Test RMSE: : {0:0.4f}\".format(accuracy.rmse(test_pred, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.001205425858379"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svdpp.estimate(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.586393803201304"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svdpp.estimate(1, 1) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.252213504313376"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svdpp.estimate(1, 47) # true rating 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.447500159589599"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svdpp.estimate(1, 3809) # true rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0005355757020338"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_svdpp.estimate(1, 4006) # true rating 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
